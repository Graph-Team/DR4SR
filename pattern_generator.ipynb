{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from copy import deepcopy\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from utils.reparam_module import ReparamModule\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19412\n"
     ]
    }
   ],
   "source": [
    "data = torch.load('./pattern-toys-noise-50.pth')\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42384\n"
     ]
    }
   ],
   "source": [
    "# Example to show how to find frequent sequential patterns\n",
    "# from a given sequence database subject to constraints\n",
    "from sequential.seq2pat import Seq2Pat, Attribute\n",
    "\n",
    "# data = [\n",
    "#     [1,2,112,2223,3,134],\n",
    "#     [1,2,6456,324,1521345,123],\n",
    "#     [1,2,125,4365,23421,203985],\n",
    "#     [2,3,12358,4532,23541,38954],\n",
    "#     [2,3,353,4234,45453,4678],\n",
    "#     [2,3,234,3342,11234,465],\n",
    "# ]\n",
    "\n",
    "# Seq2Pat over 3 sequences\n",
    "seq2pat = Seq2Pat(sequences=data, n_jobs=2, max_span=10)\n",
    "# Patterns that occur at least twice (A-D)\n",
    "patterns = seq2pat.get_patterns(min_frequency=2)\n",
    "patterns_value = [_[:-1] for _ in patterns]\n",
    "patterns_count = [_[-1] for _ in patterns]\n",
    "# print(patterns)\n",
    "print(len(patterns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109361"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_train = torch.load('./dataset/amazon-toys-seq-noise-50/toy/train_ori.pth')\n",
    "len(original_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[76], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(test):\n\u001b[1;32m     11\u001b[0m     last_item \u001b[38;5;241m=\u001b[39m _[seq_len[idx] \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m---> 12\u001b[0m     succesor_list \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mwhere(\u001b[43mtest\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlast_item\u001b[49m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m succesor \u001b[38;5;129;01min\u001b[39;00m succesor_list:\n\u001b[1;32m     14\u001b[0m         new_patterns\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m     15\u001b[0m             patterns_value_copy[idx] \u001b[38;5;241m+\u001b[39m \\\n\u001b[1;32m     16\u001b[0m             patterns_value_copy[succesor][\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m     17\u001b[0m         )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test = [torch.tensor(_) for _ in patterns_value]\n",
    "test = pad_sequence(test, batch_first=True)\n",
    "seq_len = test.bool().sum(-1)\n",
    "patterns_value_copy = deepcopy(patterns_value)\n",
    "while(True):\n",
    "    test = [torch.tensor(_) for _ in patterns_value_copy]\n",
    "    test = pad_sequence(test, batch_first=True)\n",
    "    seq_len = test.bool().sum(-1)\n",
    "    new_patterns = []\n",
    "    for idx, _ in enumerate(test):\n",
    "        last_item = _[seq_len[idx] - 1]\n",
    "        succesor_list = torch.where(test[:, 0] == last_item)[0]\n",
    "        if len(succesor_list) > 0:\n",
    "            for succesor in succesor_list:\n",
    "                new_patterns.append(\n",
    "                    patterns_value_copy[idx] + \\\n",
    "                    patterns_value_copy[succesor][1:]\n",
    "                )\n",
    "        else:\n",
    "            new_patterns.append(\n",
    "                _\n",
    "            )\n",
    "    print(len(new_patterns))\n",
    "    if len(new_patterns) == len(patterns_value_copy):\n",
    "        break\n",
    "    patterns_value = new_patterns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_len = 50\n",
    "def truncate_or_pad(seq):\n",
    "    cur_seq_len = len(seq)\n",
    "    if cur_seq_len > max_seq_len:\n",
    "        return seq[-max_seq_len:]\n",
    "    else:\n",
    "        return seq + [0] * (max_seq_len - cur_seq_len)\n",
    "\n",
    "\n",
    "train_set = set()\n",
    "\n",
    "for pattern in patterns:\n",
    "    seq = pattern[:-1]\n",
    "    seq_len = len(seq)\n",
    "    for _ in range(1, seq_len):\n",
    "        train_set.add(tuple(\n",
    "            truncate_or_pad(seq[:_]) + [seq[_]],\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42384\n",
      "109361\n"
     ]
    }
   ],
   "source": [
    "train_list = []\n",
    "for _ in train_set:\n",
    "    train_list.append([\n",
    "        0,\n",
    "        list(_)[:-1],\n",
    "        list(_)[-1],\n",
    "        sum([a != 0 for a in list(_)[:-1]]),\n",
    "        1,\n",
    "        0\n",
    "    ])\n",
    "print(len(train_list))\n",
    "print(len(original_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.choice(np.arange(5), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "semantic_augmented_train_list = []\n",
    "all_target_item = np.array([_[2] for _ in train_list])\n",
    "seq_array = np.array([_[1] for _ in train_list])\n",
    "seq_len = np.array([_[3] for _ in train_list])\n",
    "all_idx = np.arange(len(train_list))\n",
    "for idx, _ in enumerate(train_list):\n",
    "    real_seq, target_item = _[1][:_[3]], _[2]\n",
    "    match_idx = (all_target_item == target_item) & (all_idx != idx)\n",
    "    match_seq = seq_array[match_idx]\n",
    "    match_seq_len = seq_len[match_idx]\n",
    "    if len(match_seq) > 0:\n",
    "        selected_idx = np.random.choice(np.arange(len(match_seq)), 1)[0]\n",
    "        selected_seq = match_seq[selected_idx][:match_seq_len[selected_idx]].tolist()\n",
    "        new_seq = truncate_or_pad(selected_seq + real_seq)\n",
    "        semantic_augmented_train_list.append([\n",
    "            0,\n",
    "            new_seq,\n",
    "            target_item,\n",
    "            sum([a != 0 for a in list(new_seq)]),\n",
    "            1,\n",
    "            0\n",
    "        ])\n",
    "    else:\n",
    "        semantic_augmented_train_list.append(_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(train_list + original_train, 'train_new.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(semantic_augmented_train_list + original_train, 'train_new-sem.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(train_list, 'train_new-pure.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
