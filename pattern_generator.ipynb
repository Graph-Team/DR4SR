{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from copy import deepcopy\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from utils.reparam_module import ReparamModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11268\n"
     ]
    }
   ],
   "source": [
    "data = torch.load('./pattern-toys.pth')\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23426\n"
     ]
    }
   ],
   "source": [
    "# Example to show how to find frequent sequential patterns\n",
    "# from a given sequence database subject to constraints\n",
    "from sequential.seq2pat import Seq2Pat, Attribute\n",
    "\n",
    "# data = [\n",
    "#     [1,2,112,2223,3,134],\n",
    "#     [1,2,6456,324,1521345,123],\n",
    "#     [1,2,125,4365,23421,203985],\n",
    "#     [2,3,12358,4532,23541,38954],\n",
    "#     [2,3,353,4234,45453,4678],\n",
    "#     [2,3,234,3342,11234,465],\n",
    "# ]\n",
    "\n",
    "# Seq2Pat over 3 sequences\n",
    "seq2pat = Seq2Pat(sequences=data, n_jobs=2, max_span=10)\n",
    "# Patterns that occur at least twice (A-D)\n",
    "patterns = seq2pat.get_patterns(min_frequency=2)\n",
    "patterns_value = [_[:-1] for _ in patterns]\n",
    "patterns_count = [_[-1] for _ in patterns]\n",
    "# print(patterns)\n",
    "print(len(patterns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = [torch.tensor(_) for _ in patterns_value]\n",
    "test = pad_sequence(test, batch_first=True)\n",
    "seq_len = test.bool().sum(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30288\n"
     ]
    }
   ],
   "source": [
    "new_patterns = deepcopy(patterns)\n",
    "for idx, _ in enumerate(test):\n",
    "    last_item = _[seq_len[idx] - 1]\n",
    "    succesor_list = torch.where(test[:, 0] == last_item)[0]\n",
    "    for succesor in succesor_list:\n",
    "        count = min(patterns_count[succesor], patterns_count[idx])\n",
    "        if count > 3:\n",
    "            new_patterns += [\n",
    "                patterns_value[idx] + \\\n",
    "                patterns_value[succesor][1:] + \\\n",
    "                [count]\n",
    "            ]\n",
    "print(len(new_patterns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "patterns = new_patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61616"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_train = torch.load('./dataset/amazon-toys-seq/toy/train_ori.pth')\n",
    "len(original_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_len = 20\n",
    "def truncate_or_pad(seq):\n",
    "    cur_seq_len = len(seq)\n",
    "    if cur_seq_len > max_seq_len:\n",
    "        return seq[-max_seq_len:]\n",
    "    else:\n",
    "        return seq + [0] * (max_seq_len - cur_seq_len)\n",
    "\n",
    "\n",
    "train_set = set()\n",
    "\n",
    "for _ in original_train:\n",
    "    train_set.add(tuple(_[1] + [_[2]]))\n",
    "\n",
    "for pattern in patterns:\n",
    "    seq = pattern[:-1]\n",
    "    seq_len = len(seq)\n",
    "    for _ in range(1, seq_len):\n",
    "        train_set.add(tuple(\n",
    "            truncate_or_pad(seq[:_]) + [seq[_]],\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88344\n",
      "61616\n"
     ]
    }
   ],
   "source": [
    "train_list = []\n",
    "for _ in train_set:\n",
    "    train_list.append([\n",
    "        0,\n",
    "        list(_)[:-1],\n",
    "        list(_)[-1],\n",
    "        sum([a != 0 for a in list(_)[:-1]]),\n",
    "        1,\n",
    "        0\n",
    "    ])\n",
    "print(len(train_list))\n",
    "print(len(original_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(train_list + original_train, 'train_new-high3.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(train_list, 'train_new-filter.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
