{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/Lab/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from copy import deepcopy\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from utils.reparam_module import ReparamModule\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enviroment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 2024\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'beauty'\n",
    "full_dataset_name = 'amazon-beauty'\n",
    "num_item_dict = {\n",
    "    'toy': 11925,\n",
    "    'sport': 18358,\n",
    "    'beauty':12102,\n",
    "}\n",
    "path = f'./{dataset_name}-pair.pth'\n",
    "data = torch.load(path)\n",
    "num_item = num_item_dict[dataset_name]\n",
    "SOS = num_item\n",
    "EOS = num_item + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "source, target = [], []\n",
    "source_seqlen, target_seqlen = [], []\n",
    "for _ in data:\n",
    "    s, t = _\n",
    "    source_seqlen.append(len(s) + 2)\n",
    "    target_seqlen.append(len(t) + 2)\n",
    "    s = torch.tensor([SOS] + s + [EOS])\n",
    "    t = torch.tensor([SOS] + t + [EOS])\n",
    "    source.append(s)\n",
    "    target.append(t)\n",
    "source = pad_sequence(source, batch_first=True, padding_value=0)\n",
    "target = pad_sequence(target, batch_first=True, padding_value=0)\n",
    "if target.shape[1] < 20:\n",
    "    target = torch.cat([target, torch.zeros(target.shape[0], 20 - target.shape[1], dtype=torch.int)], dim=-1)\n",
    "source_seqlen = torch.tensor(source_seqlen)\n",
    "target_seqlen = torch.tensor(target_seqlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(\n",
    "            self,\n",
    "            source,\n",
    "            target,\n",
    "            source_seqlen,\n",
    "            target_seqlen,\n",
    "        ) -> None:\n",
    "        super().__init__()\n",
    "        self.source = source.to('cuda')\n",
    "        self.target = target.to('cuda')\n",
    "        self.source_seq_len = source_seqlen.to('cuda')\n",
    "        self.target_seq_len = target_seqlen.to('cuda')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.source)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        src = self.source[index]\n",
    "        tgt = self.target[index]\n",
    "        src_len = self.source_seq_len[index]\n",
    "        tgt_len = self.target_seq_len[index]\n",
    "        return src, tgt, src_len, tgt_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import normal_initialization\n",
    "from module.layers import SeqPoolingLayer\n",
    "\n",
    "class ConditionEncoder(nn.Module):\n",
    "    def __init__(self, K) -> None:\n",
    "        super().__init__()\n",
    "        transformer_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=64,\n",
    "            nhead=2,\n",
    "            dim_feedforward=256,\n",
    "            dropout=0.5,\n",
    "            activation='gelu',\n",
    "            layer_norm_eps=1e-12,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.encoder = nn.TransformerEncoder(\n",
    "            encoder_layer=transformer_layer,\n",
    "            num_layers=2,\n",
    "        )\n",
    "        self.condition_layer = nn.Sequential(\n",
    "            nn.Linear(64, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, K),\n",
    "        )\n",
    "        self.condition_emb = nn.Embedding(K, 64)\n",
    "        self.pooling_layer = SeqPoolingLayer('mean')\n",
    "        self.tau = 1\n",
    "\n",
    "    def forward(self, trm_input, src_mask, memory_key_padding_mask, src_seqlen):\n",
    "        trm_out = self.encoder(\n",
    "            src=trm_input,\n",
    "            mask=src_mask,  # BxLxD\n",
    "            src_key_padding_mask=memory_key_padding_mask,\n",
    "        )\n",
    "        trm_out = self.pooling_layer(trm_out, src_seqlen) # BD\n",
    "        condition = self.condition_layer(trm_out) # BK\n",
    "        condition = F.gumbel_softmax(condition, tau=self.tau, dim=-1) # BK\n",
    "        self.condition4loss = condition\n",
    "        self.tau = max(self.tau * 0.995, 0.1)\n",
    "        rst = condition @ self.condition_emb.weight # BD\n",
    "        return rst.unsqueeze(1)\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        # self.item_embedding = nn.Embedding(num_item + 2, 64, padding_idx=0)\n",
    "        # self.item_embedding_decoder = nn.Embedding(num_item + 2, 64, padding_idx=0)\n",
    "        self.transformer = nn.Transformer(\n",
    "            d_model=64,\n",
    "            nhead=2,\n",
    "            num_encoder_layers=2,\n",
    "            num_decoder_layers=2,\n",
    "            dim_feedforward=256,\n",
    "            dropout=0.5,\n",
    "            activation='gelu',\n",
    "            layer_norm_eps=1e-12,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.position_embedding = torch.nn.Embedding(50, 64)\n",
    "        self.condition_encoder = ConditionEncoder(5)\n",
    "        self.device = 'cuda'\n",
    "        self.apply(normal_initialization)\n",
    "        self.load_pretrained()\n",
    "\n",
    "    def load_pretrained(self):\n",
    "        # path = 'saved/SASRec7/amazon-toys-seq-noise-50/2024-01-24-17-16-57-368371.ckpt'\n",
    "        path = 'saved/SASRec/amazon-beauty-noise-50/2024-01-25-10-39-46-322830.ckpt'\n",
    "        saved = torch.load(path, map_location='cpu')\n",
    "        pretrained = saved['parameters']['item_embedding.weight']\n",
    "        pretrained = torch.cat([\n",
    "            pretrained,\n",
    "            nn.init.normal_(torch.zeros(2, 64), std=0.02)\n",
    "        ])\n",
    "        self.item_embedding = nn.Embedding.from_pretrained(pretrained, padding_idx=0, freeze=False)\n",
    "        self.item_embedding_decoder = self.item_embedding\n",
    "\n",
    "    def condition_mask(self, logits, src):\n",
    "        mask = torch.zeros_like(logits, device=logits.device, dtype=torch.bool)\n",
    "        mask = mask.scatter(-1, src.unsqueeze(-2).repeat(1, mask.shape[1], 1), 1)\n",
    "        logits = torch.masked_fill(logits, ~mask, -torch.inf)\n",
    "        return logits\n",
    "\n",
    "    def forward(self, src, tgt, src_mask, tgt_mask,\n",
    "            src_padding_mask,\n",
    "            tgt_padding_mask,\n",
    "            memory_key_padding_mask,\n",
    "            src_seqlen,\n",
    "            tgt_seqlen,\n",
    "        ):\n",
    "        position_ids = torch.arange(src.size(1), dtype=torch.long, device=self.device)\n",
    "        position_ids = position_ids.reshape(1, -1)\n",
    "        src_position_embedding = self.position_embedding(position_ids)\n",
    "        src_emb = self.dropout(self.item_embedding(src) + src_position_embedding)\n",
    "\n",
    "        con_emb = self.condition_encoder(src_emb, src_mask, src_padding_mask, src_seqlen)\n",
    "\n",
    "        position_ids = torch.arange(tgt.size(1), dtype=torch.long, device=self.device)\n",
    "        position_ids = position_ids.reshape(1, -1)\n",
    "        tgt_position_embedding = self.position_embedding(position_ids)\n",
    "        tgt_emb = self.dropout(\n",
    "            torch.cat([con_emb, self.item_embedding(tgt[:, 1:])], dim=1) + \\\n",
    "            tgt_position_embedding\n",
    "        ) # replace [SOS] with condition embedding\n",
    "\n",
    "        outs = self.transformer(\n",
    "            src_emb, tgt_emb, src_mask, tgt_mask, None,\n",
    "            src_padding_mask, tgt_padding_mask, memory_key_padding_mask\n",
    "        )\n",
    "        logits = outs @ self.item_embedding_decoder.weight.T\n",
    "        logits = self.condition_mask(logits, src)\n",
    "\n",
    "        return logits\n",
    "    \n",
    "    def encode(self, src, src_mask):\n",
    "        position_ids = torch.arange(src.size(1), dtype=torch.long, device=self.device)\n",
    "        position_ids = position_ids.reshape(1, -1)\n",
    "        src_position_embedding = self.position_embedding(position_ids)\n",
    "        src_emb = self.dropout(self.item_embedding(src) + src_position_embedding)\n",
    "\n",
    "        return self.transformer.encoder(src_emb, src_mask)\n",
    "\n",
    "    def set_condition(self, condition):\n",
    "        self.condition = condition\n",
    "\n",
    "    def decode(self, tgt, memory, tgt_mask):\n",
    "        # position_ids = torch.arange(tgt.size(1), dtype=torch.long, device=self.device)\n",
    "        # position_ids = position_ids.reshape(1, -1)\n",
    "        # tgt_position_embedding = self.position_embedding(position_ids)\n",
    "        # tgt_emb = self.dropout(self.item_embedding(tgt) + tgt_position_embedding)\n",
    "        \n",
    "        # return self.transformer.decoder(tgt_emb, memory, tgt_mask)\n",
    "        con_emb = self.condition_encoder.condition_emb.weight[self.condition].unsqueeze(0).unsqueeze(0)\n",
    "        position_ids = torch.arange(tgt.size(1), dtype=torch.long, device=self.device)\n",
    "        position_ids = position_ids.reshape(1, -1)\n",
    "        tgt_position_embedding = self.position_embedding(position_ids)\n",
    "        if tgt.shape[1] == 1:\n",
    "            # only SOS in\n",
    "            tgt_emb = self.dropout(con_emb + tgt_position_embedding)\n",
    "        else:\n",
    "            # replace SOS with Condition embedding\n",
    "            tgt_emb = self.dropout(\n",
    "                torch.cat([con_emb, self.item_embedding(tgt[:, 1:])], dim=1) + \\\n",
    "                tgt_position_embedding\n",
    "            )\n",
    "        \n",
    "        return self.transformer.decoder(tgt_emb, memory, tgt_mask)\n",
    "\n",
    "def generate_square_subsequent_mask(sz):\n",
    "    mask = (torch.triu(torch.ones((sz, sz), device='cuda')) == 1).transpose(0, 1)\n",
    "    mask = mask.float().masked_fill(mask == 0, -100000).masked_fill(mask == 1, float(0.0))\n",
    "    return mask\n",
    "\n",
    "def create_mask(src, tgt):\n",
    "    src_seq_len = src.shape[1]\n",
    "    tgt_seq_len = tgt.shape[1]\n",
    "\n",
    "    tgt_mask = generate_square_subsequent_mask(tgt_seq_len)\n",
    "    # src_mask = torch.zeros((src_seq_len, src_seq_len),device='cuda').type(torch.bool)\n",
    "    src_mask = generate_square_subsequent_mask(src_seq_len)\n",
    "\n",
    "    src_padding_mask = (src == 0)\n",
    "    tgt_padding_mask = (tgt == 0)\n",
    "    return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "NUM_EPOCHS = 80\n",
    "model = Generator().to('cuda')\n",
    "loss_fn = nn.CrossEntropyLoss(ignore_index=0)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.98), eps=1e-9)\n",
    "dataset = MyDataset(source, target, source_seqlen, target_seqlen)\n",
    "lr_scheduler = CosineAnnealingLR(\n",
    "    optimizer,\n",
    "    T_max=NUM_EPOCHS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, optimizer):\n",
    "    model.train()\n",
    "    losses = 0\n",
    "    train_dataloader = DataLoader(dataset, batch_size=256, shuffle=True)\n",
    "    for src, tgt, src_seqlen, tgt_seqlen in tqdm(train_dataloader):\n",
    "        tgt_input = tgt[:, :-1]\n",
    "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
    "        logits = model(\n",
    "            src, tgt_input, src_mask, tgt_mask,\n",
    "            src_padding_mask, tgt_padding_mask, src_padding_mask,\n",
    "            src_seqlen, tgt_seqlen)\n",
    "        optimizer.zero_grad()\n",
    "        tgt_out = tgt[:, 1:]\n",
    "        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
    "        condition_prob = model.condition_encoder.condition4loss\n",
    "        reg_loss = - (condition_prob * torch.log(condition_prob + 1e-12)).sum(-1).mean()\n",
    "        losses += loss.item()\n",
    "        loss = loss + 1 * reg_loss\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "    return losses / len(list(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:44<00:00,  2.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Train loss: 2.474, Epoch time = 45.244s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:42<00:00,  3.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Train loss: 1.733, Epoch time = 42.602s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:42<00:00,  3.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Train loss: 1.620, Epoch time = 42.904s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:42<00:00,  3.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Train loss: 1.563, Epoch time = 43.217s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:38<00:00,  3.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Train loss: 1.523, Epoch time = 38.707s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:36<00:00,  3.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, Train loss: 1.494, Epoch time = 37.025s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:36<00:00,  3.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7, Train loss: 1.474, Epoch time = 36.451s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:35<00:00,  3.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8, Train loss: 1.461, Epoch time = 36.155s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:35<00:00,  3.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9, Train loss: 1.447, Epoch time = 35.683s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:35<00:00,  3.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Train loss: 1.434, Epoch time = 36.447s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:35<00:00,  3.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11, Train loss: 1.418, Epoch time = 35.687s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:34<00:00,  3.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12, Train loss: 1.411, Epoch time = 35.383s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:34<00:00,  3.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13, Train loss: 1.408, Epoch time = 35.352s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:35<00:00,  3.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14, Train loss: 1.402, Epoch time = 36.155s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:35<00:00,  3.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15, Train loss: 1.399, Epoch time = 36.028s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:35<00:00,  3.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16, Train loss: 1.390, Epoch time = 35.623s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:34<00:00,  3.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17, Train loss: 1.378, Epoch time = 35.434s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:35<00:00,  3.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18, Train loss: 1.376, Epoch time = 35.775s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:35<00:00,  3.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19, Train loss: 1.374, Epoch time = 35.859s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:35<00:00,  3.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20, Train loss: 1.370, Epoch time = 35.721s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:35<00:00,  3.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21, Train loss: 1.366, Epoch time = 35.848s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:35<00:00,  3.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22, Train loss: 1.362, Epoch time = 35.664s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:35<00:00,  3.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23, Train loss: 1.355, Epoch time = 36.308s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:35<00:00,  3.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24, Train loss: 1.351, Epoch time = 36.115s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:35<00:00,  3.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25, Train loss: 1.351, Epoch time = 36.098s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:35<00:00,  3.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 26, Train loss: 1.350, Epoch time = 36.215s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:35<00:00,  3.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 27, Train loss: 1.346, Epoch time = 36.165s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:35<00:00,  3.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 28, Train loss: 1.341, Epoch time = 36.335s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:35<00:00,  3.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 29, Train loss: 1.334, Epoch time = 36.130s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:35<00:00,  3.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30, Train loss: 1.333, Epoch time = 36.131s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:32<00:00,  4.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 31, Train loss: 1.334, Epoch time = 33.295s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:34<00:00,  3.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 32, Train loss: 1.335, Epoch time = 34.709s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:35<00:00,  3.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 33, Train loss: 1.330, Epoch time = 36.241s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:35<00:00,  3.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 34, Train loss: 1.323, Epoch time = 36.149s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:35<00:00,  3.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 35, Train loss: 1.319, Epoch time = 36.165s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:35<00:00,  3.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 36, Train loss: 1.318, Epoch time = 35.935s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:35<00:00,  3.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 37, Train loss: 1.320, Epoch time = 36.017s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:35<00:00,  3.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 38, Train loss: 1.318, Epoch time = 36.089s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:35<00:00,  3.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 39, Train loss: 1.313, Epoch time = 36.122s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:35<00:00,  3.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 40, Train loss: 1.308, Epoch time = 36.000s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:35<00:00,  3.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 41, Train loss: 1.304, Epoch time = 35.685s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:35<00:00,  3.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 42, Train loss: 1.304, Epoch time = 35.937s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:34<00:00,  3.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 43, Train loss: 1.304, Epoch time = 35.441s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:35<00:00,  3.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 44, Train loss: 1.307, Epoch time = 35.904s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:35<00:00,  3.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 45, Train loss: 1.302, Epoch time = 35.770s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:35<00:00,  3.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 46, Train loss: 1.294, Epoch time = 35.806s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:34<00:00,  3.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 47, Train loss: 1.291, Epoch time = 35.307s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:35<00:00,  3.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 48, Train loss: 1.292, Epoch time = 36.387s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:34<00:00,  3.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 49, Train loss: 1.295, Epoch time = 35.356s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:35<00:00,  3.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 50, Train loss: 1.293, Epoch time = 35.429s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:35<00:00,  3.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 51, Train loss: 1.289, Epoch time = 35.814s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:34<00:00,  3.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 52, Train loss: 1.285, Epoch time = 34.628s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:34<00:00,  3.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 53, Train loss: 1.280, Epoch time = 34.537s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:32<00:00,  4.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 54, Train loss: 1.281, Epoch time = 33.261s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:32<00:00,  4.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 55, Train loss: 1.283, Epoch time = 33.167s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:34<00:00,  3.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 56, Train loss: 1.284, Epoch time = 35.396s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:35<00:00,  3.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 57, Train loss: 1.280, Epoch time = 36.100s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:35<00:00,  3.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 58, Train loss: 1.274, Epoch time = 35.835s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:35<00:00,  3.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 59, Train loss: 1.270, Epoch time = 36.188s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:35<00:00,  3.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 60, Train loss: 1.274, Epoch time = 36.255s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:34<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 61, Train loss: 1.273, Epoch time = 35.282s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:34<00:00,  3.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 62, Train loss: 1.274, Epoch time = 35.076s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:35<00:00,  3.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 63, Train loss: 1.271, Epoch time = 35.822s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:35<00:00,  3.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 64, Train loss: 1.265, Epoch time = 36.288s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:34<00:00,  3.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 65, Train loss: 1.260, Epoch time = 35.085s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:34<00:00,  3.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 66, Train loss: 1.264, Epoch time = 34.640s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:35<00:00,  3.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 67, Train loss: 1.264, Epoch time = 36.049s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:36<00:00,  3.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 68, Train loss: 1.264, Epoch time = 37.019s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:35<00:00,  3.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 69, Train loss: 1.260, Epoch time = 35.537s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:35<00:00,  3.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 70, Train loss: 1.258, Epoch time = 35.900s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:36<00:00,  3.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 71, Train loss: 1.253, Epoch time = 36.679s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:35<00:00,  3.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 72, Train loss: 1.258, Epoch time = 36.405s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:36<00:00,  3.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 73, Train loss: 1.255, Epoch time = 36.466s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:35<00:00,  3.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 74, Train loss: 1.255, Epoch time = 35.671s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:35<00:00,  3.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 75, Train loss: 1.254, Epoch time = 35.764s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:33<00:00,  3.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 76, Train loss: 1.249, Epoch time = 34.348s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:32<00:00,  4.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 77, Train loss: 1.247, Epoch time = 33.140s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:29<00:00,  4.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 78, Train loss: 1.249, Epoch time = 29.591s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:33<00:00,  3.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 79, Train loss: 1.251, Epoch time = 34.323s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:35<00:00,  3.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 80, Train loss: 1.248, Epoch time = 35.579s\n"
     ]
    }
   ],
   "source": [
    "from timeit import default_timer as timer\n",
    "\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS+1):\n",
    "    start_time = timer()\n",
    "    train_loss = train_epoch(model, optimizer)\n",
    "    end_time = timer()\n",
    "    print((f\"Epoch: {epoch}, Train loss: {train_loss:.3f}, \"f\"Epoch time = {(end_time - start_time):.3f}s\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f'translator-{dataset_name}-con.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_mask(logits, src, ys):\n",
    "    mask = torch.zeros_like(logits, device=logits.device, dtype=torch.bool)\n",
    "    mask = mask.scatter(-1, src, 1)\n",
    "    mask = mask.scatter(-1, ys, 0)\n",
    "    logits = torch.masked_fill(logits, ~mask, -torch.inf)\n",
    "    return logits\n",
    "\n",
    "def greedy_decode(model, src, src_mask, max_len, start_symbol):\n",
    "    src = src.to('cuda')\n",
    "    src_mask = src_mask.to('cuda')\n",
    "\n",
    "    memory = model.encode(src, src_mask)\n",
    "    ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to('cuda')\n",
    "    for i in range(max_len-1):\n",
    "        memory = memory.to('cuda')\n",
    "        tgt_mask = (generate_square_subsequent_mask(ys.size(1))\n",
    "                    .type(torch.bool)).to('cuda')\n",
    "        out = model.decode(ys, memory, tgt_mask)\n",
    "        prob = out[:, -1] @ model.item_embedding_decoder.weight.T\n",
    "        prob = inference_mask(prob, src, ys)\n",
    "        _, next_word = torch.max(prob, dim=-1)\n",
    "        next_word = next_word.item()\n",
    "\n",
    "        ys = torch.cat([ys,\n",
    "                        torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=1)\n",
    "        if next_word == EOS:\n",
    "            break\n",
    "    return ys\n",
    "\n",
    "def translate(model: torch.nn.Module, src):\n",
    "    model.eval()\n",
    "    src = src.reshape(1, -1)\n",
    "    num_tokens = src.shape[1]\n",
    "    src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n",
    "    tgt_tokens = greedy_decode(\n",
    "        model, src, src_mask, max_len=25, start_symbol=SOS).flatten()\n",
    "    return tgt_tokens\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(seq):\n",
    "    return torch.tensor([SOS] + seq + [EOS], device='cuda')\n",
    "original_data = torch.load(f'./dataset/{full_dataset_name}-noise-50/{dataset_name}/train_ori.pth')\n",
    "seqlist = [_[1][:_[3]] + [_[2][_[3] - 1]] for _ in original_data]\n",
    "seqlist = [preprocess(_) for _ in seqlist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(f'translator-{dataset_name}-con.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([12102, 10812, 10897,  1135, 10669, 10689,  1166, 10896, 11734, 11732,\n",
      "         7114, 11772, 11773, 11768, 11853, 11878, 11879, 11774, 11775,  8976,\n",
      "         8977, 11767,     5,   918,  1015,  1076,  1592,  1977,  2414,  2835,\n",
      "         2837,  2841,  3564,  5580,  9939,  4505,  3387,   366, 11710, 11712,\n",
      "        11805, 11807,  6440,  6456,   388,   417,   420,  1902,  2313, 12103])\n",
      "tensor([12102, 11767, 11768, 12103], device='cuda:0')\n",
      "tensor([12102, 11774, 11775, 12103,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n"
     ]
    }
   ],
   "source": [
    "idx = 30\n",
    "# model.condition = 0\n",
    "model.set_condition(1)\n",
    "print(source[idx])\n",
    "print(translate(model, source[idx]))\n",
    "print(target[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:11<00:00,  8.54it/s]\n"
     ]
    }
   ],
   "source": [
    "model.condition = 3\n",
    "filtered_sequences = []\n",
    "for seq in tqdm(seqlist[:100]):\n",
    "    rst = translate(model, seq)\n",
    "    filtered_sequences.append(rst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug = deepcopy(filtered_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "for a, b in zip(debug, filtered_sequences):\n",
    "    if len(a) == len(b):\n",
    "        if (a == b).all():\n",
    "            cnt += 1\n",
    "print(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111815\n"
     ]
    }
   ],
   "source": [
    "interval = list(range(0, 25001, 5000))\n",
    "rst_list = []\n",
    "for i in range(len(interval) - 1):\n",
    "    rst_list.append(torch.load(f'f-seq-con-{dataset_name}-{interval[i]}-{interval[i + 1]}.pth'))\n",
    "rst = []\n",
    "for _ in rst_list:\n",
    "    rst += _\n",
    "print(len(rst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89210"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ori_pattern = torch.load(f'./dataset/{full_dataset_name}-noise-50/{dataset_name}/train_new-pure.pth')\n",
    "ori_seqlist = [list(_[1][:_[3]]) + [_[2][_[3] - 1]] for _ in list(ori_pattern)]\n",
    "len(ori_pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22326\n"
     ]
    }
   ],
   "source": [
    "max_seq_len = 50\n",
    "def truncate_or_pad(seq):\n",
    "    cur_seq_len = len(seq)\n",
    "    if cur_seq_len > max_seq_len:\n",
    "        return seq[-max_seq_len:]\n",
    "    else:\n",
    "        return seq + [0] * (max_seq_len - cur_seq_len)\n",
    "\n",
    "train_set = set()\n",
    "# for _ in ori_seqlist:\n",
    "#     train_set.add(tuple(_))\n",
    "\n",
    "for pattern in rst:\n",
    "    seq = pattern.tolist()[1:-1]\n",
    "    train_set.add(tuple(seq))\n",
    "print(len(train_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22326\n"
     ]
    }
   ],
   "source": [
    "train_list = []\n",
    "for _ in train_set:\n",
    "    train_list.append([\n",
    "        1,\n",
    "        truncate_or_pad(list(_)[:-1]),\n",
    "        truncate_or_pad(list(_)[1:]),\n",
    "        sum([a != 0 for a in list(_)[:-1]]),\n",
    "        [1] * max_seq_len,\n",
    "        [0] * max_seq_len,\n",
    "    ])\n",
    "print(len(train_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(train_list + ori_pattern, f'./dataset/{full_dataset_name}-noise-50/{dataset_name}/train_gene.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
